{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification (1) – an issue with distance measures, and an implementation of Nearest Neighbour classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will expand on some of the concepts of \n",
    "classification, starting with an experiment with distance measures on data, then looking into the $k$-Nearest Neighbour algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn\n",
    "# calculate distance O(n)\n",
    "# sort distances O(n)quicksort\n",
    "# select k-smallest O(n)\n",
    "# majority voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Distance measures for high-dimensionality data\n",
    "\n",
    "Algorithms such as $k$-Nearest Neighbour are conceptually very simple -- we predict the class value of an unlabelled *query* data point we are given by looking at all the labelled data point(s) in our data set, and predicting that our query will have the same class as the most similar data point(s) in the training set. So, all we need is a way of measuring similarity. The well-known *Euclidean distance measure* would seem to be a good choice. However, while we are very familiar with Euclidean distance in 2 and 3-dimensions, there was a warning (Slide 62 of the \"Classification (1)\" lecture) that in high-dimensions there is a problem – what was this problem ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise distances in high-dimensional spaces \n",
    "\n",
    "**Answer**: in high-dimensional spaces everything is far away from everything else, and so pairwise distances become uninformative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what does this actually mean ? There is a mathematical argument to show that this is a true statement, but an alternative approach is simply to simulate what happens. One approach is to randomly generate $N$ points inside a $d$-dimensional cube centred around zero, such as $[-0.5, 0.5]^{d}$. Now we calculate the pairwise distances among the $N$ points.  After that for every data point we calculate the ratio of the minimum distance to the maximum distance  to all of the other data points. The mean ratio represents the average range of pairwise distances there are in that dimensionality. We run the simulation from 1 dimension to 1000 dimensions and the ratios will be plotted on a line chart using the ``` matplotlib ``` library. \n",
    "\n",
    "You should use the ```numpy``` library for this, and in particular the linear algebra methods to calculate distances such as the [L2 norm](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.linalg.norm.html#numpy.linalg.norm). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run_d_n(dim,N_pts,L):\n",
    "    pts=np.random.rand(N_pts,dim)-0.5 # simulate N_pts points on dim dimensions space\n",
    "    ratio_list=[]\n",
    "    for i in range(N_pts):\n",
    "        # ignore the data point itself\n",
    "        selected_pts=np.array([j for j in range(N_pts) if j!=i])\n",
    "        # calculate the L2 or L1 distance with other points\n",
    "        dist=np.linalg.norm(pts[selected_pts]-pts[i],L,axis=1)\n",
    "        # calculate the ratio of the min. distance to the max. distance\n",
    "        ratio=np.min(dist)/np.max(dist)\n",
    "        ratio_list.append(ratio)\n",
    "    # output the mean ratio\n",
    "    return np.mean(ratio_list)\n",
    "\n",
    "# Initialise the N_pts, the number of points we simulate\n",
    "N_pts=1000\n",
    "# Setting l=2 to calculate the L2 distance\n",
    "l=1\n",
    "# Setting the number of dimensions we simulate\n",
    "check_dim=range(1,550,50)\n",
    "# Calculate the mean ratio on that dimension\n",
    "ratio_list=[ run_d_n(dim,N_pts,l) for dim in check_dim]\n",
    "# Plot the ratio with its corresponding dimension\n",
    "plt.plot(check_dim,ratio_list)\n",
    "plt.ylabel(\"Mean ratio of min/max pairwise distances\")\n",
    "plt.xlabel(\"Number of dimensions\")\n",
    "plt.title(\"Effect of increasing dimensionality on pairwise distances\")\n",
    "plt.xticks(np.arange(0, 600, step=100))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** how can this plot be interpreted ? How else could you visualize this effect ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Implement Nearest Neighbour from scratch\n",
    "\n",
    "The following will give some practise in implementing a simple classifier, the $k$-Nearest Neighbour ($k$NN) algorithm. It should help us to write a $k$NN package from scratch. Most machine learning methods include two main steps, namely training (fitting to a model to the training data) and prediction (running the model on input data  to generate output). However, in the $k$NN algorithm, since there is no explicit model-building step, we only require implementation of the prediction step without a training step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_01 = np.array([1, 0.5])\n",
    "cov_01 = np.array([[1, 0.1], [0.1, 1.2]])\n",
    "\n",
    "mean_02 = np.array([4, 5])\n",
    "cov_02 = np.array([[1, 0.1], [0.1, 1.2]])\n",
    "\n",
    "dist_01 = np.random.multivariate_normal(mean_01, cov_01, 500)\n",
    "dist_02 = np.random.multivariate_normal(mean_02, cov_02, 500)\n",
    "print(dist_01.shape, dist_02.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created two 2-dimensional normal distributions of data points with the same covariance but different means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the created Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the data look like ? Notice the 2 unique clusters being formed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.xlim(-5, 10)\n",
    "plt.ylim(-5, 10)\n",
    "\n",
    "plt.scatter(dist_01[:, 0], dist_01[:, 1])\n",
    "plt.scatter(dist_02[:, 0], dist_02[:, 1])#, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now represent it in a tabular way. We will have dist_01 getting label 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = dist_01.shape[0] + dist_02.shape[0]\n",
    "c = dist_01.shape[1] + 1\n",
    "data = np.zeros((r, c))\n",
    "print(data.shape)\n",
    "\n",
    "data[:dist_01.shape[0], :2] = dist_01\n",
    "data[dist_01.shape[0]:, :2] = dist_02\n",
    "data[dist_01.shape[0]:, -1] = 1.0\n",
    "\n",
    "print(data.mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now shuffle the data and check by printing the first 10 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.69580675 -1.93653681  0.        ]\n",
      " [ 0.60651478  1.40500059  0.        ]\n",
      " [-0.62356204 -0.38127599  0.        ]\n",
      " [-0.83759617  0.87589313  0.        ]\n",
      " [-0.20304232  0.13027859  0.        ]\n",
      " [ 4.1084201   4.33488963  1.        ]\n",
      " [ 4.29655838  5.18035077  1.        ]\n",
      " [ 0.91081662  1.30417127  0.        ]\n",
      " [ 2.22119298  3.78771419  1.        ]\n",
      " [ 3.12388626  0.77992393  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(data)\n",
    "print(data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation.** Next, we implement our KNN algorithm. There are many ways to do this, but a basic approach will require a pairwise distance measure for instances, and a way to take a \"training\" dataset of classified instances and make a prediction for a \"test\" data instance. Here is a top-level outline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "def distance(x1, x2):\n",
    "    #TODO\n",
    "    dis = np.sum((x1 - x2) ** 2, axis=1) ** 0.5\n",
    "    return dis\n",
    "    \n",
    "def knn(X_train, y_train, xt, k=7):\n",
    "    #TODO\n",
    "    k_labels = [y_train[index] for index in distance(X_train, xt).argsort()[0:k]]\n",
    "    label = collections.Counter(k_labels).most_common(1)[0][0]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check to see if we can make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "test_point = np.array([8, -4])\n",
    "# a = distance(data[:, :2], test_point)\n",
    "# print(a)\n",
    "# Un-comment the line below and check if it comes out as 0.0  \n",
    "print(knn(data[:, :2], data[:, -1], test_point))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a train and test split of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 2) (750,)\n",
      "(250, 2) (250,)\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(data)\n",
    "split = int(0.75 * data.shape[0])\n",
    "# print split\n",
    "train_data_X = data[:split, :2]\n",
    "train_data_y = data[:split, -1]\n",
    "test_data_X = data[split:, :2]\n",
    "test_data_y = data[split:, -1]\n",
    "\n",
    "print(train_data_X.shape, train_data_y.shape)\n",
    "print(test_data_X.shape, test_data_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation.** Next we need to implement some way to run our KNN classifier on all the test data and get the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.6%\n"
     ]
    }
   ],
   "source": [
    "# np.random.shuffle(data)\n",
    "# split = int(0.75 * data.shape[0])\n",
    "# # print split\n",
    "# train_data_X = data[:split, :2]\n",
    "# train_data_y = data[:split, -1]\n",
    "# test_data_X = data[split:, :2]\n",
    "# test_data_y = data[split:, -1]\n",
    "def get_acc(kx):\n",
    "    error = 0\n",
    "    for j in range(test_data_y.shape[0]):\n",
    "        if (test_data_y[j] != knn(train_data_X,train_data_y, test_data_X[j], kx)):\n",
    "            error = error + 1\n",
    "        else:\n",
    "            error = error\n",
    "#     print(error)\n",
    "    rate =  (test_data_y.shape[0] - error) / test_data_y.shape[0] * 100\n",
    "    return str(rate) + '%'\n",
    "print(get_acc(7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What accuracy did you get ? You should get around 99 percent on this dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try different values of K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 2 | Acc: 98.0%\n",
      "k: 3 | Acc: 99.2%\n",
      "k: 4 | Acc: 98.8%\n",
      "k: 5 | Acc: 99.6%\n",
      "k: 6 | Acc: 99.6%\n",
      "k: 7 | Acc: 99.6%\n",
      "k: 8 | Acc: 99.6%\n",
      "k: 9 | Acc: 99.6%\n",
      "k: 10 | Acc: 98.8%\n",
      "k: 11 | Acc: 99.2%\n",
      "k: 12 | Acc: 98.8%\n",
      "k: 13 | Acc: 98.8%\n",
      "k: 14 | Acc: 98.4%\n",
      "k: 15 | Acc: 98.8%\n",
      "k: 16 | Acc: 98.4%\n",
      "k: 17 | Acc: 98.4%\n",
      "k: 18 | Acc: 98.4%\n",
      "k: 19 | Acc: 98.0%\n"
     ]
    }
   ],
   "source": [
    "for ix in range(2, 20):\n",
    "    print (\"k:\", ix, \"| Acc:\", get_acc(ix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's try real data : MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, MNIST is image data, but here we are using a CSV version where we can view the pixels as numbers (each row has the pixel data for an image of a digit, and the first column is the class of the digit, i.e., 0-9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>...</th>\n",
       "      <th>0.608</th>\n",
       "      <th>0.609</th>\n",
       "      <th>0.610</th>\n",
       "      <th>0.611</th>\n",
       "      <th>0.612</th>\n",
       "      <th>0.613</th>\n",
       "      <th>0.614</th>\n",
       "      <th>0.615</th>\n",
       "      <th>0.616</th>\n",
       "      <th>0.617</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   5  0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  ...  0.608  0.609  0.610  \\\n",
       "0  0  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "1  4  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "2  1  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "3  9  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "4  2  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "\n",
       "   0.611  0.612  0.613  0.614  0.615  0.616  0.617  \n",
       "0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dataset is quite big, we will just use a subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 785)\n"
     ]
    }
   ],
   "source": [
    "data = df.values[:2000]\n",
    "print (data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a train/test split of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 784) (1600,)\n",
      "(400, 784) (400,)\n"
     ]
    }
   ],
   "source": [
    "split = int(0.8 * data.shape[0])\n",
    "\n",
    "X_train = data[:split, 1:]\n",
    "X_test = data[split:, 1:]\n",
    "\n",
    "y_train = data[:split, 0]\n",
    "y_test = data[split:, 0]\n",
    "\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us just check that our data really does represent images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(0)\n",
    "plt.imshow(X_train[91].reshape((28, 28)), cmap='gray', interpolation='none')\n",
    "print (y_train[91])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation.** Now code another ```get_acc()``` and try different values of K on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.25%\n"
     ]
    }
   ],
   "source": [
    "def get_acc(kx):\n",
    "    #TODO\n",
    "    error = 0\n",
    "    for j in range(X_test.shape[0]):\n",
    "        if (y_test[j] != knn(X_train,y_train, X_test[j], kx)):\n",
    "            error = error + 1\n",
    "        else:\n",
    "            error = error\n",
    "#     print(error)\n",
    "    rate =  (y_test.shape[0] - error) / y_test.shape[0] * 100\n",
    "    return str(rate) + '%'\n",
    "\n",
    "print(get_acc(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
